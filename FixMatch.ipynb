{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younesBoutiyarzist/FixMatch/blob/main/FixMatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREATE MODEL"
      ],
      "metadata": {
        "id": "4Vhg6pn2uDlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JNxGjqNPS2Jn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout\n",
        "from tensorflow.keras.layers import Dense, Flatten,BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def create_model(image_size=32):\n",
        "# initialize the model along with the input shape to be\n",
        "# \"channels last\" and the channels dimension itself\n",
        "  model = Sequential()\n",
        "  chanDim = -1\n",
        "\n",
        "  # CONV => RELU => POOL\n",
        "  model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(image_size,image_size,3)))\n",
        "  model.add(BatchNormalization(axis=chanDim))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "  # (CONV => RELU) * 2 => POOL\n",
        "  model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "  model.add(BatchNormalization(axis=chanDim))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "  # (CONV => RELU) * 2 => POOL\n",
        "  model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "  model.add(BatchNormalization(axis=chanDim))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "  # (CONV => RELU) * 2 => POOL\n",
        "  model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
        "  model.add(BatchNormalization(axis=chanDim))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # first (and only) set of FC => RELU layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # softmax classifier\n",
        "  model.add(Dense(18,activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "LKODCH2luSPM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea7E3-6l3_le"
      },
      "source": [
        "IMPORT DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "animal data :"
      ],
      "metadata": {
        "id": "hR8cdSaFZ4E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/axelcarlier/projsemisup.git\n",
        "path = \"./projsemisup/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kUHP48_Z3uf",
        "outputId": "fb45e76e-22ed-4e93-8aca-8be4d51b2b6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'projsemisup'...\n",
            "remote: Enumerating objects: 48161, done.\u001b[K\n",
            "remote: Total 48161 (delta 0), reused 0 (delta 0), pack-reused 48161\u001b[K\n",
            "Receiving objects: 100% (48161/48161), 2.96 GiB | 30.09 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n",
            "Checking out files: 100% (22857/22857), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CLASSES = os.listdir(path + 'Lab/')\n",
        "print(CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXcDJT2naBlk",
        "outputId": "cc9cecab-c8d6-4193-f8a3-c5a7a85e5749"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hyène', 'Gorilla', 'autruche', 'Hippopotame', 'Guepard', 'Lion', 'Girafe', 'tigre', 'Rhinoceros', 'Gnou', \"Buffle d'Afrique\", 'Phacochère', 'Zèbre', 'Chimpanzé', 'antilope', 'Leopard', 'Chacal', 'Elephant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32"
      ],
      "metadata": {
        "id": "0Hax0OB_aCZz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_semisup_data(path, classes, image_size=64, nb_unlab=7*360):\n",
        "\n",
        "  file_path_lab = os.listdir(path + 'Lab/')\n",
        "  nb_lab = 360\n",
        "  # Initialise les structures de données\n",
        "  x_lab = np.zeros((nb_lab, image_size, image_size, 3))\n",
        "  y_lab = np.zeros((nb_lab, 1))\n",
        "  i = 0\n",
        "  for c in file_path_lab:\n",
        "\n",
        "    class_label = classes.index(c)\n",
        "    list_images = os.listdir(path + 'Lab/' + c + '/')\n",
        "\n",
        "    for img_name in list_images:\n",
        "      # Lecture de l'image\n",
        "      img = Image.open(path + 'Lab/' + c + '/' + img_name)\n",
        "      # Mise à l'échelle de l'image\n",
        "      img = img.resize((image_size,image_size), Image.ANTIALIAS)\n",
        "      img = img.convert('RGB')\n",
        "      # Remplissage de la variable x\n",
        "      x_lab[i] = np.asarray(img)\n",
        "      y_lab[i] = class_label\n",
        "      i = i + 1\n",
        "\n",
        "\n",
        "  file_path_test = os.listdir(path + 'Test/')\n",
        "  nb_test = 1800\n",
        "  # Initialise les structures de données\n",
        "  x_test = np.zeros((nb_test, image_size, image_size, 3))\n",
        "  y_test = np.zeros((nb_test, 1))\n",
        "  i = 0\n",
        "  for c in file_path_test:\n",
        "\n",
        "    class_label = classes.index(c)\n",
        "    list_images = os.listdir(path + 'Test/' + c + '/')\n",
        "\n",
        "    for img_name in list_images:\n",
        "      # Lecture de l'image\n",
        "      img = Image.open(path + 'Test/' + c + '/' + img_name)\n",
        "      # Mise à l'échelle de l'image\n",
        "      img = img.resize((image_size,image_size), Image.ANTIALIAS)\n",
        "      img = img.convert('RGB')\n",
        "      # Remplissage de la variable x\n",
        "      x_test[i] = np.asarray(img)\n",
        "      y_test[i] = class_label\n",
        "      i = i + 1\n",
        "\n",
        "  x_unlab = np.zeros((nb_unlab, image_size, image_size, 3))\n",
        "  i = 0\n",
        "  list_images = os.listdir(path + 'Unlab/')\n",
        "  nb_unlab_dir = len(list_images)\n",
        "  for img_name in list_images:\n",
        "    # Lecture de l'image\n",
        "    img = Image.open(path + 'Unlab/' + img_name)\n",
        "    # Mise à l'échelle de l'image\n",
        "    img = img.resize((image_size,image_size), Image.ANTIALIAS)\n",
        "    img = img.convert('RGB')\n",
        "    # Remplissage de la variable x\n",
        "    x_unlab[i] = np.asarray(img)\n",
        "    i = i + 1\n",
        "    if (i >= nb_unlab or i >= nb_unlab_dir):\n",
        "      break;\n",
        "\n",
        "\n",
        "\n",
        "  return x_lab, y_lab, x_test, y_test, x_unlab\n",
        "\n",
        "x_lab, y_lab, x_test, y_test, x_unlab = load_semisup_data(path, CLASSES, image_size=IMAGE_SIZE)"
      ],
      "metadata": {
        "id": "ktjnwWhaaFv2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imgaug.augmenters as iaa\n",
        "aug_strong = iaa.RandAugment(m=(4, 9))\n",
        "aug_weak = iaa.RandAugment(m=(0, 3))\n",
        "\n",
        "def randaugment_weak(img):\n",
        "  return aug_weak(images=img)\n",
        "\n",
        "def randaugment_strong(img):\n",
        "  return aug_strong(images=img)"
      ],
      "metadata": {
        "id": "cznEg23eX8Vh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Augmentation puis des données\n",
        "x_batch_augment = randaugment_strong(x_lab.astype('uint8'))\n",
        "#x_batch_augment = train_lab_X.astype('float')/255\n",
        "plt.imshow(x_batch_augment[1,:,:].astype('float')/255)\n",
        "plt.show()\n",
        "plt.imshow(x_lab[1,:,:].astype('float')/255)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "kKOG22NVYKQD",
        "outputId": "5f9352e3-0fd4-4fc6-f596-0cffa7bfe10d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeKElEQVR4nO2dW4xk13We/3VOXfveMz13UuJFlBTaMUmhwciwIMg2bDCKEUpBIIgPAh8EjxFYQAQ4D4QCRAqQBzmIJOhJwSgiTCeKLrEkiDCYxArjQHAAkxopFEmRpkhRQ4ujmemeW1/qfuqsPFQxGDL7392c7q4ec/8fMJjqs2qfs86us+pU7b/WWubuEEK89cn22wEhxGRQsAuRCAp2IRJBwS5EIijYhUgEBbsQiVDZyWAzuw/AFwHkAP6Du3829vxGo+4zM1NBWzEs6LhiWIaPX7u+96oyoja6h48FACXxg20HAB/yg+WVnNqyasSWGbVVsvC4wYDPr5fc/8y4H5GpghEXPfKSxebeIy+aDyN+VIgjsYuATy+yauwEIqaIxM2unyxyfXgRHjPo9lH0i+AZ2PXq7GaWA/gpgN8B8CqAHwB4wN2fY2OWlhb9/n/8m0HbpStX6LEubraD27PjdTrGK/xF6Q/41THo9qltc2MzuL290aFjepcH1LZwZI7aZo/OUluz0aC2xZmF4PYLZ8/TMf02P+ep6jy1FV3+BlIhQVE2eEAPBtyPbovPY9nir6cdJPezNvfdIgE9daxJbd7j4wZDfo1013vB7TMH+dx3V8PX4s+ffBGd9XYw2HfyMf5eAC+5+8vu3gfwdQD372B/Qog9ZCfBfgLAL675+9XxNiHEDcieL9CZ2UkzO21mp7vd8McVIcTes5NgPwvg5mv+vmm87XW4+yl3X3b35UaDf8cWQuwtOwn2HwC4w8xuNbMagI8CeHR33BJC7DbXLb25e2FmnwDw3zGS3h5295/ExtRrDdxy4l1B26EmXy2+3Lsa3H6+bNExfeMqQ22Kf8IYTvGVbieaTD2LqAJTfPW5uThNbTFpqF7jL1uRhVet5w/xlX+LaE1hEWdE2eN+1Abh+0hvyL/KlUMuNVUqEWm2GvG/F17h766FV7MBYOZQWNEAgKnGDLVt9Da4H32uGNSnw9dcpc7Pa+Z4WK2JSYM70tnd/TEAj+1kH0KIyaBf0AmRCAp2IRJBwS5EIijYhUgEBbsQibCj1fg3fbA8x9LBsKwxO7dIxy2shWW5+fZFOuaXZUQGiaRJ9fpc8pojUln+Nj6NlakqtQ0j2XJFJCmkLLh8Va2F5ZpsnidwZLUatfVKfqxOhyd3gCQbVddi9xc+j/UmlzfLg3werRaW89pzXGK1Lr8G2lfWqa1X8vkoeR4PlVKHHX6dNqrha9Ei92/d2YVIBAW7EImgYBciERTsQiSCgl2IRJjoarwZUCMJKtUGT4Ko2lGyQ36sjT5f/uwbX72d5ovWKLKw7/3Iqnq5wW21WiTZpc5X8Qc9PlfDjfB59xt8PlqrvCRYyYrJAWh1utQ2sxieyGLAV/cHkXJhR287Tm3XUyevu8hX96+e50kyXePnPBVJiKotcFvnYlh5ufyzy/xY1fDK/zBSKkx3diESQcEuRCIo2IVIBAW7EImgYBciERTsQiTCZKU3ABXS0qaM6GjTU+Ex1ZzLMdV1Ll29uPYLamvVuTRUy8PT5cbfMzukBhoA5AX3sRJJTvFpLud1Lob9LyNJFc0ql4VmDkW6kkS6qmxcWAtub0QSUPKIJBpreZXVuYRpw/B5T1f43PtxXhtwesj9z0gSEgC0NsJdjQCgrIZfs/qRSD05kjxjP43ME7UIId5SKNiFSAQFuxCJoGAXIhEU7EIkgoJdiETYkfRmZmcAbAAYAijcfTn+fEeVtCcaDLkreR6W3oqMSz+LC0vUdhepSwYAL7d4G6pfFuE2VM16JNvpIJfQ+j0uNQ3Bs9SakXZHRrKrBpH39doMn/teh89xXuE+1urhOW7Uw22LAKAyG2lrFcmwa21yH4csk64bkXoPc1kuj/QmXV3hWWp5zq8DkDqFzciYehaWALNsj9o/jflNd+eVH4UQNwT6GC9EIuw02B3AX5jZD83s5G44JITYG3b6Mf597n7WzA4D+J6Z/Y27f//aJ4zfBE4CwNIB/tNLIcTesqM7u7ufHf+/AuA7AO4NPOeUuy+7+/LsTKQfuRBiT7nuYDezaTObfe0xgN8F8OxuOSaE2F128jH+CIDv2KggYQXAf3b3/xYf4jAPZ4GVBc9cquRhmYQk/gAA+gMux1Qi8s8dkeKFlV74vXEl0mpqNiKfFE0u/6ytc/87Ay55lbWwnJdFMvPaG1zWapMClgAwPcPPbendh4gfdEi0gOhwyDWvqSF/PTcuhbPNNtotOqYs+TXQucqzGDfPRdpy1fn8ezX8WmeRbMSDx8NFWPNaJJOSWrbA3V8GcNf1jhdCTBZJb0IkgoJdiERQsAuRCAp2IRJBwS5EIky04CQcMCcyWpVLb8MinLlUr3P3fRAp8BfRf7zJm729gxS4zDordMyZTZ4jNN/g0tXcPJddel3+Hl0QFe1SK5yxBwD5DJeabr7jBLUNwCW71Yurwe0LzTk6plrj5zUsuARYjfxWa+YAud5mp+iYQcazEZsVXnDy+K28AOrmxjq1NabDMmUvIg9eWb0Q3B6bJ93ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEmGz7JzNkpO1OPdL6p09a+EQWbzGzxHPnNzc71BZrQ1Xk4ZX6d1WO0DEHqnzV97l1Xu9uUOFJFc0mf9lmWT28Kl+lLaqRue9u8nGR1fi1C+HVZ5/jfhw+dJDaKm2uGFjJW1sVFk5cMdKGDACKDX59VGtcJZk/yhNyFg7wBJVWJ6zKFBv8vNYuh9WV4SDSQotahBBvKRTsQiSCgl2IRFCwC5EICnYhEkHBLkQiTFx6q5EaWdWIFOLdsMTT6XIZp9HgCQuzM1wO22jxBJpRmfz/n/r0DB1x2xQ/VjOSdPO/V16gttWrPKllajq8T69wSbGWcTmpJElIANCIjHvH7eEEmlaby3WbLS43zjR5tktu/Nwy0uapiNTxa3okWaeMHCsiH1cafK4Ga1eC24fOE2Hq5JLLeBjpzi5EKijYhUgEBbsQiaBgFyIRFOxCJIKCXYhE2FJ6M7OHAfwegBV3/9XxtgMAvgHgFgBnAHzE3cP6wet3BmPaQMazgmr1sNzR63NpYvUil6cOHTpAbfNzXHYxIr39ryefoWNmpniduaNLi9yPy/ylac5yGWrQC8s/3YiENgS3gb8sqDv3sU4yBH3ItaFeyVsrFRlvh+WRmoK9MnyN5JE2X+Uw0nrrMq+VmHlE95qO9LYircqqkblvLIQl3azC79/bubP/CYD73rDtIQCPu/sdAB4f/y2EuIHZMtjH/dYvv2Hz/QAeGT9+BMCHdtkvIcQuc73f2Y+4+7nx4/MYdXQVQtzA7HiBzt0d7HekAMzspJmdNrPT6xv8O7YQYm+53mC/YGbHAGD8P+2S4O6n3H3Z3ZfnIgtLQoi95XqD/VEAD44fPwjgu7vjjhBir9iO9PY1AB8AsGRmrwL4NIDPAvimmX0cwCsAPrLtI5IP/JlF3nfysGzhJc9cqkQkiOEwMi7j4xok8+rSFV6U8WKLS2+/3ORS0wsv8GKUD/yTD1Db2c1LYT+GvP3QRocXWNzscptFJK+MSKm1kutJWWR/RS+SfRfJHnQiK5aRy21Qi8h8Q+5jJaJTtjv8GpnKwv4vHeefhDeL8LWTR+Zwy2B39weI6be3GiuEuHHQL+iESAQFuxCJoGAXIhEU7EIkgoJdiESYaMFJd0d/EJYMsojklRPTVKSYY7vD5bWVSxvUtjDHiwbW62GJ5NeXf4WO+U//9UlqO7rEM+zuWr6L2iznPcVunwtLL8O1SK8340Ug25GEuDLjxu4wvM96jUuRc9kCPxbJDAOAsuS2ZjM8x90+HzMc8MKXcJ71VjjfZ7XC5cFhN7zPzRaX65ATmc8jcijfmxDirYSCXYhEULALkQgKdiESQcEuRCIo2IVIhH2Q3sLSVp5z2YJlvdUj/bPKSGbbcMjlkwurPDusUgnLRlmk19grr/wttU3ZQWp7563c9otLa9T2rkPhJmBvby7RMQdqXMo7Yzz77nyb+5FXw5dWu8dlrW7kGpgquGRnLf56Dlm2XJOP8T6XFAvntjxSIbJ0fj0y2dk3eb/CIbn0I8qg7uxCpIKCXYhEULALkQgKdiESQcEuRCJMdDUeMFojq9vhyRheC69yDiKr6rGEAC95skuW8yk5txJeqV9Y5LXC3n08vDoOAAt8sRVd0sYJAK6u/5La3n7gncHt89M86WYOfK4WSSIJAPz13/6E2i72w8lGHpnfsuQr3a0an48ikiSzWJ8Pbq/yxXHUq/yF6UUiZrW9Sm3NkqsJWTV8z610InUU26R+YRFpT0UtQoi3FAp2IRJBwS5EIijYhUgEBbsQiaBgFyIRttP+6WEAvwdgxd1/dbztMwB+H8BrWsOn3P2x7RyQqV6W59zJStjmkZZReSxJZp3X9qrXuOwyIMpQZtz3X/v7YSkMAF786QvUduXyRWqrNbmcx+axjCRwGG/Ci5Krcpiv8jm2XlgOWy3bdEynxdthFQPuYy3nstaValgCPNw4QMfMRmobvtq6QG1eROTBCrd1PXzec/O8Jt+gJHNFYgXY3p39TwDcF9j+BXe/e/xvW4EuhNg/tgx2d/8+gMsT8EUIsYfs5Dv7J8zsaTN72MwWd80jIcSecL3B/iUAtwO4G8A5AJ9jTzSzk2Z22sxOb2y2rvNwQoidcl3B7u4X3H3o7iWALwO4N/LcU+6+7O7LszP8N+RCiL3luoLdzI5d8+eHATy7O+4IIfaK7UhvXwPwAQBLZvYqgE8D+ICZ3Q3AAZwB8AfbOZh7iWERlgxyUt8NAMphWLYoBjxTDjV+anmNS0bdXofa5ufDn0yKPq+rtsmykwCsbXL/s1Uu8SwcjsiURCrzSE2+do/7WK/yY91z4u9R22r3SnD72dYKHbOW87ZcV/p8rrpMEwXgRFa8UHBps2xxWW4p48tTwxr3Y9O45FhDeFyvy2v89UlfLh9yH7YMdnd/ILD5K1uNE0LcWOgXdEIkgoJdiERQsAuRCAp2IRJBwS5EIky04KQByMnbi0eKDfaHYT2pVo0U8avwVjwHD/LMtssrXBoaksKG9QoveHh4gWeonZnitiIih730Nzxb7r3vvi24/cAiPxYyPlcr53lxywp7MQHkU+HX5sT0YTpmznm2WbPBZah2zmXFFsmWa7W4xLrS5rLciZlD1LY0zWU5W+NZe20P+zKVR14zC8uUWaR4qO7sQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSIQJ93oDrTjJikoCo2y54K4iMgMKLodZ5LTnFsK9wQCg0wlnt9XrXMqbn+a2qxs8k2sq51LkbJ1Ljt1OOLuqmOWy1kyDv+f3Fric5LEilll4n2WkOGeZ8f1dGfAiocVmJFOxGT7vZoPP4UqbV2G7sMJlucZCk9rqkflvdsO27ibPpgTbXeT2rTu7EImgYBciERTsQiSCgl2IRFCwC5EIE12NdwcGpJ6cRVZiMwuvupeRelsWObNBn6/eViP16Sqkjlg54KumzSleUfemEyeorbfOV32PH4kkk8yS45E5BIBhyZM0DkYSaHoFH9dph8uGVyNtvhYi7Y7qbX5f+nnknnWlHX5t8pz7PrvAV85R5/N4deMqtZXOfVxszob9mOKr+61NUq+Pd5nSnV2IVFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJsJ32TzcD+FMARzBq93TK3b9oZgcAfAPALRi1gPqIu4d7/oxxOIZEehtWuBTCWto4uIxjEVmOtZMa7ZPXfivIdA1avLVPvcoTYVirJgCYW5ijthZJyAEAJxJPPZL40e/zpKFOj9d3q9b4Pqenw5Ld+vo6HROTB+tVLofdMnuE2g40wjLr+as82aWMnHMvEjHOS/lhruDGohdOiGqX/HWukYPZDmvQFQD+yN3vBPBeAH9oZncCeAjA4+5+B4DHx38LIW5Qtgx2dz/n7j8aP94A8DyAEwDuB/DI+GmPAPjQXjkphNg5b+o7u5ndAuAeAE8AOOLu58am8xh9zBdC3KBsO9jNbAbAtwB80t1f98XL3R0I98Y1s5NmdtrMTm9u8u+2Qoi9ZVvBbmZVjAL9q+7+7fHmC2Z2bGw/BiDYXcHdT7n7srsvz8xEfnMshNhTtgx2MzOM+rE/7+6fv8b0KIAHx48fBPDd3XdPCLFbbCfr7TcAfAzAM2b21HjbpwB8FsA3zezjAF4B8JEt9+RA6WGJjZSZAwB0i7A0UY9kqJWkZRTAa9oBQFFw2SVnGVsRyWhAsr8A4LkXf0Zt77/zJmorelymzEjtt16PS5HwiLyWR7LlIhImS7+q17gE1YpImHmVv9b1Cv/EWC/CUursNB/T7/D5Xe+QbDMAR2a5XHq4zmv5nVsNy4CdPn9dDpKadrGWXFsGu7v/FUDFu9/earwQ4sZAv6ATIhEU7EIkgoJdiERQsAuRCAp2IRJhsgUn4SjLcIZVtxuTccIUxrO1KhGJpyi4DOWkPRUAGDmel3x/a5Esr2LAxw0i7avuedet1DYchsddXVujY5q1yHt+pMVTpc4LIuaVcEacRV6XdodnMXY6vEhovcH3OVcLZ9+t9bjMt9aNZOZFJN2rl/i4vMFDLS/D8x8rmhpReym6swuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIRJt/rjfYH4xJPvRqWZIpYr7eCv49lkX5jw4iMxiQ7J5l8QFwyWpznfdTmZrmt6PF99jbCNT9r07yPWq8fkdcyfm42iBRmjBRtZAwjsme1yotbtjZ4Jlq1Fi74udiYp2NubXDZc5MUhwSAdh6RFbt8XKMSzujrdPkcXtnYDG7vRyRb3dmFSAQFuxCJoGAXIhEU7EIkgoJdiESY6Gq8GZCTGmmxH/abhceUJOkDAAbhytYAgFpzmtqKAa8Zx6pzTTX5SvGrV3g7qZuOHqa2hcWD3IvICjmG4RVci6gdRSQHKbYaH1MhWFHB9bXwKjIAzMxzxaAgySIAYDF1hdQUnM4il/4cX6m/eJGv/Dcyfh04zxlCWQnP1fEa92OetMP6ce1pOkZ3diESQcEuRCIo2IVIBAW7EImgYBciERTsQiTCltKbmd0M4E8xasnsAE65+xfN7DMAfh/A6vipn3L3x2L7KoclWq2wtNVshhMWAKBCpJVajbuf5dw2HPSorV7nbYYqFfLeGEme+ZXbjlFbP9IaKtYEMzMueVWIxJaXXAJEznWhHk1cAqaqkVZDJHlpaoHLazElD85l1n6f2+rkGul1Ix2Fh9yRt81yufTi2iVqO9rkUmrPw9fj2oDLfFc74Xp3sUSu7ejsBYA/cvcfmdksgB+a2ffGti+4+7/bxj6EEPvMdnq9nQNwbvx4w8yeB3Birx0TQuwub+o7u5ndAuAeAE+MN33CzJ42s4fNjLepFELsO9sOdjObAfAtAJ9093UAXwJwO4C7Mbrzf46MO2lmp83sdKvNiy4IIfaWbQW7mVUxCvSvuvu3AcDdL7j70EfNzr8M4N7QWHc/5e7L7r48PRX5gbAQYk/ZMtjNzAB8BcDz7v75a7Zfu8z8YQDP7r57QojdYjur8b8B4GMAnjGzp8bbPgXgATO7GyM57gyAP9hqR5ZlaDTDd/dYBlWP1HHzOs8yykueRpdFMuxqDb5Plpnnkf297aaj1NZZ5y2Zui2eHVaf4vXpBv1wrbNYW6talcs1XeeXyCDSvmp2OlyPzSISGjJew21Q8El20lIMAEoiReWk7hsAwHgW3VyF26w4QG2xuoc5qW24CT7m55cvBLf3Ipmg21mN/yuEczujmroQ4sZCv6ATIhEU7EIkgoJdiERQsAuRCAp2IRJhsgUnARgpBFlGpCEmWwwGERmHFKkEgGqdSzxlRAKskEw6VhATAIYl319Wi0iHPS67sGKOAJCTFkRDUogSAIZtLvPVpnjRw/6Qy2GtVlgCrJJsOADII9l8APe/0uCv59pmWLYdRjLbClKkEgAGfZ49eDCS0TeIXAe2GZbe6h7ObAOAg3Ozwe2VjM+v7uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhIlKbw6AJPggyyN9ski/sVrkraqacXmK9f8CAC8jWU0k7S0mvZURyatW5/n9ZUTiGfZ4wcysSmQoj/RDG3Afq30uyzWaXGpqExeziOwZK9w5iGQx1iIXQo1kqWWx7DXS0w8Asoi01evwAqJW4eedV8PX/qHpQ3TM0bDyhv9ZeZKO0Z1diERQsAuRCAp2IRJBwS5EIijYhUgEBbsQiTBR6S3PDIszYZkhJq0wEa0SqRyZkew6ABhGMuyGQy7/VEnxxYiKE5XlPJK9VqnygoiDLq+/n9Fzi/Rli2TfDXr8WPVaOLNtZAv37ovdXbIskqkYUew6kX4EVTIwi1QJ7XX5tVNvcLl0/QrvH7f66qvUdvREuMFSLdJ38NKl1eD22PWrO7sQiaBgFyIRFOxCJIKCXYhEULALkQhbrsabWQPA9wHUx8//M3f/tJndCuDrAA4C+CGAj7k7z94A0OoV+OsXLwdtxw/xjs9H5tiKKq9B55FVcKPr+0CtxldAS1JHbNDnfmR5rF4cX8av1sOr2QBQ6cV8DB+vGjkvd76CG2sbVfb4anxzNny8TmSumpFacpVKbKWeqwmdTjgjpxpZ6W42IvMbUXliK/WzC7w1FKtrNzU1RcfMzYeTkGLX1Hbu7D0Av+Xud2HUnvk+M3svgD8G8AV3fweAKwA+vo19CSH2iS2D3Ue8ludYHf9zAL8F4M/G2x8B8KE98VAIsStstz97Pu7gugLgewB+BuCq+//7HP0qgPAvA4QQNwTbCnZ3H7r73QBuAnAvgHdv9wBmdtLMTpvZ6U6Hf8cTQuwtb2o13t2vAvhLAL8OYMHMXlvguwnAWTLmlLsvu/tys8kXnYQQe8uWwW5mh8xsYfy4CeB3ADyPUdD/0/HTHgTw3b1yUgixc7aTCHMMwCNmlmP05vBNd/9zM3sOwNfN7N8A+D8AvrLVji6vbeAbjz0etDUj0tDbbrk1uP0f/YN3cqdneaKDR97jYu2fjLRWQqRt0WDA1cgylrQQSQrJI1kh3gknY2R57Jz5XFnGfSwG/GtZpRv2o94kxdMAFMOIJBqRvFhtQADokfp6tcinzDwi8xW9SButSEuppUOHqa1LEpu6kWNNEekwdt1sGezu/jSAewLbX8bo+7sQ4u8A+gWdEImgYBciERTsQiSCgl2IRFCwC5EI5hGpadcPZrYK4JXxn0sALk7s4Bz58Xrkx+v5u+bH29092DdqosH+ugObnXb35X05uPyQHwn6oY/xQiSCgl2IRNjPYD+1j8e+FvnxeuTH63nL+LFv39mFEJNFH+OFSIR9CXYzu8/MXjCzl8zsof3wYezHGTN7xsyeMrPTEzzuw2a2YmbPXrPtgJl9z8xeHP/PK3DurR+fMbOz4zl5ysw+OAE/bjazvzSz58zsJ2b2z8fbJzonET8mOidm1jCzJ83sx2M//vV4+61m9sQ4br5hZrzSZgh3n+g/ADlGZa1uA1AD8GMAd07aj7EvZwAs7cNx3w/gPQCevWbbvwXw0PjxQwD+eJ/8+AyAfzHh+TgG4D3jx7MAfgrgzknPScSPic4JAAMwM35cBfAEgPcC+CaAj463/3sA/+zN7Hc/7uz3AnjJ3V/2UenprwO4fx/82Dfc/fsA3lhT+36MCncCEyrgSfyYOO5+zt1/NH68gVFxlBOY8JxE/JgoPmLXi7zuR7CfAPCLa/7ez2KVDuAvzOyHZnZyn3x4jSPufm78+DyAI/voyyfM7Onxx/w9/zpxLWZ2C0b1E57APs7JG/wAJjwne1HkNfUFuve5+3sA/EMAf2hm799vh4DROzsQKc2yt3wJwO0Y9Qg4B+Bzkzqwmc0A+BaAT7r7+rW2Sc5JwI+Jz4nvoMgrYz+C/SyAm6/5mxar3Gvc/ez4/xUA38H+Vt65YGbHAGD8/8p+OOHuF8YXWgngy5jQnJhZFaMA+6q7f3u8eeJzEvJjv+ZkfOw3XeSVsR/B/gMAd4xXFmsAPgrg0Uk7YWbTZjb72mMAvwvg2fioPeVRjAp3AvtYwPO14BrzYUxgTmxURO4rAJ53989fY5ronDA/Jj0ne1bkdVIrjG9YbfwgRiudPwPwL/fJh9swUgJ+DOAnk/QDwNcw+jg4wOi718cx6pn3OIAXAfwPAAf2yY//COAZAE9jFGzHJuDH+zD6iP40gKfG/z446TmJ+DHROQHwaxgVcX0aozeWf3XNNfskgJcA/BcA9TezX/2CTohESH2BTohkULALkQgKdiESQcEuRCIo2IVIBAW7EImgYBciERTsQiTC/wVBKSLQ3crs3AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVK8itsvD72s"
      },
      "source": [
        "# Nombre d'epochs de l'apprentissage\n",
        "epochs = 2000\n",
        "# Nombre de données non-labellisées par batch\n",
        "mu = 3\n",
        "# Nombre de données labellisées par batch\n",
        "bs_lab = 64\n",
        "bs_unlab = bs_lab *mu\n",
        "\n",
        "# Taille du batch\n",
        "batch_size = bs_lab + bs_unlab\n",
        "# Valeur initiale du paramètre de contrôle de l'importance de la régularisation non-supervisée\n",
        "lambda_t = 1\n",
        "tau = 0.95\n",
        "model = create_model()\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX6CeRBaTR6h",
        "outputId": "b0c07220-dec2-4215-b173-8a5d7dba89b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4, 4, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1049600   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 18)                18450     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,458,386\n",
            "Trainable params: 1,457,426\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lab_X = x_lab\n",
        "train_lab_y = y_lab\n",
        "test_X = x_test\n",
        "test_y = y_test\n",
        "train_unlab_X = x_unlab"
      ],
      "metadata": {
        "id": "hsUCOUArf7S6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Nombre de batches par epochs\n",
        "steps_per_epochs = int(np.floor(train_lab_X.shape[0]/bs_lab))\n",
        "# Instanciation d'un optimiseur et d'une fonction de coût.\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "# ICI ON A BESOIN DE DEUX FONCTIONS DE COUT : \n",
        "# perte\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# Préparation des métriques pour le suivi de la performance du modèle.\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "# Indices de l'ensemble  labellisé\n",
        "indices_lab = np.arange(train_lab_X.shape[0]) \n",
        "# Indices de l'ensemble non labellisé\n",
        "indices_unlab = np.arange(train_unlab_X.shape[0]) \n",
        "          "
      ],
      "metadata": {
        "id": "aVfB_ywETWWz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "QhrTNf44pOz-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  for b in range(steps_per_epochs):\n",
        "\n",
        "    # Les données d'un batch sont constituées de l'intégralité de nos données labellisées...\n",
        "    x_batch_lab = train_lab_X[indices_lab[b*bs_lab:(b+1)*bs_lab]]\n",
        "    y_batch_lab = train_lab_y[indices_lab[b*bs_lab:(b+1)*bs_lab]]\n",
        "    #y_batch_lab = np.expand_dims(train_lab_y, 1)\n",
        "\n",
        "    # ... ainsi que de données non-labellisées !\n",
        "    x_batch_unlab = train_unlab_X[indices_unlab[b*bs_unlab:(b+1)*bs_unlab]]\n",
        "\n",
        "    # Les opérations effectuées par le modèle dans ce bloc sont suivies et permettront\n",
        "    # la différentiation automatique.\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Application du réseau aux données d'entrée labelisé\n",
        "      y_lab_pred = model(x_batch_lab, training=False)\n",
        "\n",
        "      # Calcul loss on lab\n",
        "      sup_term = loss(tf.squeeze(tf.one_hot(y_batch_lab, 18)), y_lab_pred)\n",
        "      unsup_term = 0\n",
        "\n",
        "      # weak augmentation\n",
        "      x_batch_unlab_weak = randaugment_weak(x_batch_unlab.astype('uint8'))\n",
        "\n",
        "      # strong augmentation\n",
        "      x_batch_unlab_strong = randaugment_strong(x_batch_unlab.astype('uint8'))\n",
        "\n",
        "      # Application du réseau aux données d'entrée non labelisé\n",
        "      y_unlab_weak_pred = model(x_batch_unlab_weak, training=False)\n",
        "      y_unlab_strong_pred = model(x_batch_unlab_strong, training=True)\n",
        "\n",
        "      # get correct prediction\n",
        "      res = np.amax(y_unlab_weak_pred,1) > tau\n",
        "      aux = np.argmax(y_unlab_weak_pred, axis=1)\n",
        "      print(sum(res))\n",
        "      if sum(res) > 0 :\n",
        "        y_unlab_weak_pred_filter = y_unlab_weak_pred[res]\n",
        "        x_batch_unlab_weak_filter = x_batch_unlab_weak[res]\n",
        "        \n",
        "        # keep prediction on strong augmentation\n",
        "        y_unlab_strong_pred_filter = y_unlab_strong_pred[res]\n",
        "        x_batch_unlab_weak_filter = x_batch_unlab_strong[res]\n",
        "\n",
        "        # Calcul loss on unlab\n",
        "        unsup_term = loss(y_unlab_weak_pred_filter, y_unlab_strong_pred_filter)\n",
        "\n",
        "      # Calcul de la fonction de perte sur ce batch\n",
        "      loss_value = sup_term + lambda_t * unsup_term\n",
        "\n",
        "      # Calcul des gradients par différentiation automatique\n",
        "      grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "\n",
        "      # Réalisation d'une itération de la descente de gradient (mise à jour des paramètres du réseau)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "      # Mise à jour de la métrique\n",
        "      train_acc_metric.update_state(tf.squeeze(tf.one_hot(y_batch_lab, 18)), y_lab_pred)\n",
        "\n",
        "  # Calcul de la précision à la fin de l'epoch\n",
        "  train_acc = train_acc_metric.result()\n",
        "  # Calcul de la précision sur l'ensemble de validation à la fin de l'epoch\n",
        "  val_logits = model(x_test, training=False)\n",
        "  val_acc_metric.update_state(tf.squeeze(tf.one_hot(y_test, 18)), val_logits)\n",
        "  val_acc = val_acc_metric.result()\n",
        "\n",
        "  print(\"Epoch %4d : Loss : %.4f, Acc : %.4f, Val Acc : %.4f\" % (epoch, float(loss_value), float(train_acc), float(val_acc)))\n",
        "\n",
        "  # Remise à zéro des métriques pour la prochaine epoch\n",
        "  train_acc_metric.reset_states()\n",
        "  val_acc_metric.reset_states()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nct5Loz-V2TD",
        "outputId": "a2d4d55a-0bff-41cb-ff96-796e570eaddd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "0\n",
            "10\n",
            "0\n",
            "0\n",
            "Epoch    0 : Loss : 5.6135, Acc : 0.0000, Val Acc : 0.0550\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    1 : Loss : 2.9598, Acc : 0.0000, Val Acc : 0.0556\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    2 : Loss : 2.7693, Acc : 0.0656, Val Acc : 0.0700\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    3 : Loss : 2.7374, Acc : 0.0656, Val Acc : 0.0717\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    4 : Loss : 2.7185, Acc : 0.0844, Val Acc : 0.0639\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    5 : Loss : 2.7234, Acc : 0.0750, Val Acc : 0.0872\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    6 : Loss : 2.7722, Acc : 0.0719, Val Acc : 0.0972\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    7 : Loss : 2.7436, Acc : 0.0969, Val Acc : 0.0994\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    8 : Loss : 2.6659, Acc : 0.1250, Val Acc : 0.1044\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Epoch    9 : Loss : 2.5516, Acc : 0.1344, Val Acc : 0.1106\n",
            "0\n",
            "0\n",
            "1\n",
            "3\n",
            "17\n",
            "Epoch   10 : Loss : 3.9279, Acc : 0.1094, Val Acc : 0.0750\n",
            "20\n",
            "23\n",
            "23\n",
            "15\n",
            "13\n",
            "Epoch   11 : Loss : 3.6920, Acc : 0.1094, Val Acc : 0.0867\n",
            "8\n",
            "19\n",
            "58\n",
            "33\n",
            "20\n",
            "Epoch   12 : Loss : 4.1357, Acc : 0.0844, Val Acc : 0.0950\n",
            "9\n",
            "5\n",
            "3\n",
            "2\n",
            "4\n",
            "Epoch   13 : Loss : 3.1036, Acc : 0.0437, Val Acc : 0.0872\n",
            "7\n",
            "11\n",
            "24\n",
            "34\n",
            "47\n",
            "Epoch   14 : Loss : 7.0005, Acc : 0.0656, Val Acc : 0.0822\n",
            "27\n",
            "19\n",
            "16\n",
            "9\n",
            "13\n",
            "Epoch   15 : Loss : 3.4241, Acc : 0.1312, Val Acc : 0.0894\n",
            "12\n",
            "12\n",
            "20\n",
            "13\n",
            "23\n",
            "Epoch   16 : Loss : 3.5815, Acc : 0.1344, Val Acc : 0.1050\n",
            "21\n",
            "21\n",
            "25\n",
            "23\n",
            "27\n",
            "Epoch   17 : Loss : 3.5210, Acc : 0.1500, Val Acc : 0.1028\n",
            "14\n",
            "12\n",
            "15\n",
            "14\n",
            "22\n",
            "Epoch   18 : Loss : 2.9843, Acc : 0.1656, Val Acc : 0.0950\n",
            "19\n",
            "19\n",
            "34\n",
            "28\n",
            "25\n",
            "Epoch   19 : Loss : 3.3104, Acc : 0.1500, Val Acc : 0.1122\n",
            "14\n",
            "16\n",
            "36\n",
            "53\n",
            "39\n",
            "Epoch   20 : Loss : 3.7848, Acc : 0.1562, Val Acc : 0.1100\n",
            "23\n",
            "12\n",
            "19\n",
            "27\n",
            "47\n",
            "Epoch   21 : Loss : 3.2387, Acc : 0.1937, Val Acc : 0.1006\n",
            "40\n",
            "45\n",
            "45\n",
            "37\n",
            "35\n",
            "Epoch   22 : Loss : 2.8143, Acc : 0.2062, Val Acc : 0.1144\n",
            "36\n",
            "25\n",
            "28\n",
            "35\n",
            "32\n",
            "Epoch   23 : Loss : 2.4355, Acc : 0.2781, Val Acc : 0.1172\n",
            "45\n",
            "61\n",
            "33\n",
            "25\n",
            "18\n",
            "Epoch   24 : Loss : 2.2922, Acc : 0.2969, Val Acc : 0.1178\n",
            "18\n",
            "21\n",
            "37\n",
            "40\n",
            "61\n",
            "Epoch   25 : Loss : 3.1420, Acc : 0.2656, Val Acc : 0.1283\n",
            "41\n",
            "38\n",
            "37\n",
            "55\n",
            "44\n",
            "Epoch   26 : Loss : 2.2098, Acc : 0.3031, Val Acc : 0.1300\n",
            "33\n",
            "36\n",
            "56\n",
            "52\n",
            "41\n",
            "Epoch   27 : Loss : 1.9425, Acc : 0.3469, Val Acc : 0.1317\n",
            "45\n",
            "78\n",
            "65\n",
            "40\n",
            "20\n",
            "Epoch   28 : Loss : 1.9029, Acc : 0.3500, Val Acc : 0.1428\n",
            "27\n",
            "46\n",
            "60\n",
            "65\n",
            "44\n",
            "Epoch   29 : Loss : 2.4142, Acc : 0.3531, Val Acc : 0.1317\n",
            "29\n",
            "25\n",
            "25\n",
            "42\n",
            "75\n",
            "Epoch   30 : Loss : 1.9765, Acc : 0.4625, Val Acc : 0.1300\n",
            "59\n",
            "53\n",
            "58\n",
            "66\n",
            "51\n",
            "Epoch   31 : Loss : 1.4392, Acc : 0.4563, Val Acc : 0.1328\n",
            "50\n",
            "56\n",
            "69\n",
            "46\n",
            "39\n",
            "Epoch   32 : Loss : 1.3488, Acc : 0.5094, Val Acc : 0.1356\n",
            "31\n",
            "41\n",
            "52\n",
            "66\n",
            "83\n",
            "Epoch   33 : Loss : 2.0785, Acc : 0.5188, Val Acc : 0.1344\n",
            "38\n",
            "39\n",
            "35\n",
            "64\n",
            "90\n",
            "Epoch   34 : Loss : 1.4321, Acc : 0.6000, Val Acc : 0.1194\n",
            "96\n",
            "62\n",
            "44\n",
            "49\n",
            "58\n",
            "Epoch   35 : Loss : 1.1229, Acc : 0.5781, Val Acc : 0.1267\n",
            "92\n",
            "94\n",
            "74\n",
            "47\n",
            "49\n",
            "Epoch   36 : Loss : 1.1927, Acc : 0.6031, Val Acc : 0.1444\n",
            "54\n",
            "68\n",
            "95\n",
            "71\n",
            "36\n",
            "Epoch   37 : Loss : 1.2088, Acc : 0.6406, Val Acc : 0.1456\n",
            "23\n",
            "25\n",
            "46\n",
            "96\n",
            "92\n",
            "Epoch   38 : Loss : 2.5012, Acc : 0.6031, Val Acc : 0.1356\n",
            "60\n",
            "32\n",
            "28\n",
            "42\n",
            "69\n",
            "Epoch   39 : Loss : 1.2281, Acc : 0.7469, Val Acc : 0.1400\n",
            "81\n",
            "84\n",
            "62\n",
            "72\n",
            "59\n",
            "Epoch   40 : Loss : 0.8263, Acc : 0.6844, Val Acc : 0.1289\n",
            "76\n",
            "79\n",
            "92\n",
            "92\n",
            "71\n",
            "Epoch   41 : Loss : 1.4923, Acc : 0.6344, Val Acc : 0.1483\n",
            "59\n",
            "64\n",
            "64\n",
            "87\n",
            "69\n",
            "Epoch   42 : Loss : 0.9521, Acc : 0.8125, Val Acc : 0.1439\n",
            "86\n",
            "73\n",
            "71\n",
            "82\n",
            "69\n",
            "Epoch   43 : Loss : 0.4806, Acc : 0.8219, Val Acc : 0.1378\n",
            "82\n",
            "78\n",
            "85\n",
            "89\n",
            "86\n",
            "Epoch   44 : Loss : 0.7714, Acc : 0.8125, Val Acc : 0.1333\n",
            "82\n",
            "85\n",
            "101\n",
            "94\n",
            "74\n",
            "Epoch   45 : Loss : 0.6200, Acc : 0.8813, Val Acc : 0.1394\n",
            "77\n",
            "85\n",
            "98\n",
            "89\n",
            "82\n",
            "Epoch   46 : Loss : 0.4834, Acc : 0.8469, Val Acc : 0.1422\n",
            "83\n",
            "84\n",
            "100\n",
            "96\n",
            "86\n",
            "Epoch   47 : Loss : 0.5388, Acc : 0.9062, Val Acc : 0.1389\n",
            "84\n",
            "76\n",
            "109\n",
            "106\n",
            "95\n",
            "Epoch   48 : Loss : 0.5641, Acc : 0.9062, Val Acc : 0.1417\n",
            "67\n",
            "66\n",
            "74\n",
            "103\n",
            "87\n",
            "Epoch   49 : Loss : 0.6372, Acc : 0.8781, Val Acc : 0.1422\n",
            "88\n",
            "85\n",
            "90\n",
            "87\n",
            "106\n",
            "Epoch   50 : Loss : 0.5216, Acc : 0.8562, Val Acc : 0.1250\n",
            "94\n",
            "98\n",
            "83\n",
            "83\n",
            "90\n",
            "Epoch   51 : Loss : 0.4749, Acc : 0.8719, Val Acc : 0.1272\n",
            "103\n",
            "95\n",
            "84\n",
            "66\n",
            "79\n",
            "Epoch   52 : Loss : 0.3878, Acc : 0.8219, Val Acc : 0.1244\n",
            "96\n",
            "109\n",
            "107\n",
            "92\n",
            "71\n",
            "Epoch   53 : Loss : 1.6339, Acc : 0.8375, Val Acc : 0.1456\n",
            "70\n",
            "75\n",
            "87\n",
            "102\n",
            "94\n",
            "Epoch   54 : Loss : 0.7451, Acc : 0.8406, Val Acc : 0.1228\n",
            "93\n",
            "85\n",
            "91\n",
            "104\n",
            "96\n",
            "Epoch   55 : Loss : 0.9702, Acc : 0.8406, Val Acc : 0.1361\n",
            "88\n",
            "78\n",
            "81\n",
            "82\n",
            "89\n",
            "Epoch   56 : Loss : 0.5016, Acc : 0.9406, Val Acc : 0.1367\n",
            "87\n",
            "98\n",
            "77\n",
            "77\n",
            "80\n",
            "Epoch   57 : Loss : 0.3375, Acc : 0.9219, Val Acc : 0.1356\n",
            "90\n",
            "94\n",
            "105\n",
            "91\n",
            "66\n",
            "Epoch   58 : Loss : 1.1346, Acc : 0.8875, Val Acc : 0.1444\n",
            "60\n",
            "73\n",
            "86\n",
            "112\n",
            "105\n",
            "Epoch   59 : Loss : 0.8109, Acc : 0.8969, Val Acc : 0.1300\n",
            "86\n",
            "60\n",
            "61\n",
            "72\n",
            "68\n",
            "Epoch   60 : Loss : 0.1870, Acc : 0.9781, Val Acc : 0.1356\n",
            "105\n",
            "100\n",
            "103\n",
            "96\n",
            "73\n",
            "Epoch   61 : Loss : 0.3407, Acc : 0.9156, Val Acc : 0.1294\n",
            "87\n",
            "74\n",
            "99\n",
            "102\n",
            "110\n",
            "Epoch   62 : Loss : 0.7701, Acc : 0.8938, Val Acc : 0.1372\n",
            "91\n",
            "73\n",
            "62\n",
            "74\n",
            "75\n",
            "Epoch   63 : Loss : 0.4163, Acc : 0.9406, Val Acc : 0.1317\n",
            "100\n",
            "104\n",
            "87\n",
            "86\n",
            "72\n",
            "Epoch   64 : Loss : 0.4012, Acc : 0.9000, Val Acc : 0.1372\n",
            "91\n",
            "88\n",
            "94\n",
            "105\n",
            "106\n",
            "Epoch   65 : Loss : 0.2784, Acc : 0.9156, Val Acc : 0.1294\n",
            "110\n",
            "90\n",
            "92\n",
            "92\n",
            "92\n",
            "Epoch   66 : Loss : 0.2306, Acc : 0.9625, Val Acc : 0.1183\n",
            "108\n",
            "108\n",
            "111\n",
            "109\n",
            "107\n",
            "Epoch   67 : Loss : 0.3941, Acc : 0.9344, Val Acc : 0.1189\n",
            "108\n",
            "95\n",
            "104\n",
            "100\n",
            "96\n",
            "Epoch   68 : Loss : 0.3123, Acc : 0.9875, Val Acc : 0.1206\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-94c04614bc1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m# weak augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mx_batch_unlab_weak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandaugment_weak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_unlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;31m# strong augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-89399d3ea4ae>\u001b[0m in \u001b[0;36mrandaugment_weak\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandaugment_weak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0maug_weak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandaugment_strong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m         \u001b[0;34m\"\"\"Alias for :func:`~imgaug.augmenters.meta.Augmenter.augment`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxtasksperchild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment\u001b[0;34m(self, return_batch, hooks, **kwargs)\u001b[0m\n\u001b[1;32m   1977\u001b[0m         )\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m         \u001b[0mbatch_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_batch_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m         \u001b[0;31m# return either batch or tuple of augmentables, depending on what\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_batch_\u001b[0;34m(self, batch, parents, hooks)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_maybe_deterministic_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_inaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m                 batch_inaug = self._augment_batch_(\n\u001b[0m\u001b[1;32m    642\u001b[0m                     \u001b[0mbatch_inaug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36m_augment_batch_\u001b[0;34m(self, batch, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3124\u001b[0;31m                 batch = self[index].augment_batch_(\n\u001b[0m\u001b[1;32m   3125\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3126\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_batch_\u001b[0;34m(self, batch, parents, hooks)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_maybe_deterministic_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_inaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m                 batch_inaug = self._augment_batch_(\n\u001b[0m\u001b[1;32m    642\u001b[0m                     \u001b[0mbatch_inaug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36m_augment_batch_\u001b[0;34m(self, batch, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   3401\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m                     \u001b[0mbatch_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubselect_rows_by_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3403\u001b[0;31m                     batch_sub = self[augmenter_index].augment_batch_(\n\u001b[0m\u001b[1;32m   3404\u001b[0m                         \u001b[0mbatch_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3405\u001b[0m                         \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_batch_\u001b[0;34m(self, batch, parents, hooks)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_maybe_deterministic_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_inaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m                 batch_inaug = self._augment_batch_(\n\u001b[0m\u001b[1;32m    642\u001b[0m                     \u001b[0mbatch_inaug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/pillike.py\u001b[0m in \u001b[0;36m_augment_batch_\u001b[0;34m(self, batch, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   1571\u001b[0m         \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/pillike.py\u001b[0m in \u001b[0;36menhance_contrast\u001b[0;34m(image, factor)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_enhance_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageEnhance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imgaug/augmenters/pillike.py\u001b[0m in \u001b[0;36m_apply_enhance_func\u001b[0;34m(image, cls, factor)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;31m# don't return np.asarray(...) as its results are read-only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     result = np.array(\n\u001b[0;32m--> 548\u001b[0;31m         cls(\n\u001b[0m\u001b[1;32m    549\u001b[0m             \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         ).enhance(factor)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/ImageEnhance.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageStat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegenerate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/ImageStat.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# calculate missing attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_get\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/ImageStat.py\u001b[0m in \u001b[0;36m_getmean\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/ImageStat.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# calculate missing attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_get\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/ImageStat.py\u001b[0m in \u001b[0;36m_getsum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mlayerSum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mlayerSum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayerSum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}